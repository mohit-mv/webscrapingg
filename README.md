# webscrapingg
The web scraping process
If you do it yourself This is what a general DIY web scraping process looks like:
Identify target website
Collect URLs of the pages where you want to extract data from
Make a request to these URLs to get the HTML of the page
Use locators to find the data in the HTML
Save the data in a JSON or CSV file or some other structured format

Simple enough, right? It is! If you just have a small project. But unfortunately, there are quite a few challenges you need to tackle if you need data at scale. For example, maintaining the scraper if the website layout changes, managing proxies, executing javascript or working around antibots. These are all deeply technical problems that can eat up a lot of resources. Thatâ€™s part of the reason many businesses choose to outsource their web data projects.
